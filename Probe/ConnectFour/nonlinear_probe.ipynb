{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from generate_embeddings_connect4 import get_embeddings_qvalues, min_max_normalization\n",
    "from probe import ProbeDataset, train_probe, test_probe\n",
    "from GPT.dataset import EpisodeDataset\n",
    "from GPT.model import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_idx = {(i, j): i * 7 + j + 1 for i in range(6) for j in range(7)}\n",
    "token_to_idx['<pad>'] = 0  # Padding token\n",
    "\n",
    "vocab_size = 43\n",
    "block_size = 42 # Honestly this could probably be whatever\n",
    "embed_size = 512\n",
    "num_heads = 8\n",
    "num_layers = 8\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, r'1\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent1 = pickle.load(f)\n",
    "with open(os.path.join(path, r'2\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent2 = pickle.load(f)\n",
    "with open(os.path.join(path, r'3\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent3 = pickle.load(f)\n",
    "with open(os.path.join(path, r'4\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent4 = pickle.load(f)\n",
    "with open(os.path.join(path, r'5\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent5 = pickle.load(f)\n",
    "with open(os.path.join(path, r'6\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent6 = pickle.load(f)\n",
    "with open(os.path.join(path, r'7\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent7 = pickle.load(f)\n",
    "with open(os.path.join(path, r'8\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent8 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, r'1\\training_data\\q_vals_games_125000.pkl'), 'rb') as f:\n",
    "    qagent1 = pickle.load(f)\n",
    "with open(os.path.join(path, r'2\\training_data\\q_vals_games_125000.pkl'), 'rb') as f:\n",
    "    qagent2 = pickle.load(f)\n",
    "with open(os.path.join(path, r'3\\training_data\\q_vals_games_125000.pkl'), 'rb') as f:\n",
    "    qagent3 = pickle.load(f)\n",
    "with open(os.path.join(path, r'4\\training_data\\q_vals_games_125000.pkl'), 'rb') as f:\n",
    "    qagent4 = pickle.load(f)\n",
    "with open(os.path.join(path, r'5\\training_data\\q_vals_games_125000.pkl'), 'rb') as f:\n",
    "    qagent5 = pickle.load(f)\n",
    "with open(os.path.join(path, r'6\\training_data\\q_vals_games_125000.pkl'), 'rb') as f:\n",
    "    qagent6 = pickle.load(f)\n",
    "with open(os.path.join(path, r'7\\training_data\\q_vals_games_125000.pkl'), 'rb') as f:\n",
    "    qagent7 = pickle.load(f)\n",
    "with open(os.path.join(path, r'8\\training_data\\q_vals_games_125000.pkl'), 'rb') as f:\n",
    "    qagent8 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "valid_ratio = 0.1\n",
    "\n",
    "d1 = len(agent1)\n",
    "d2 = len(agent2)\n",
    "d3 = len(agent3)\n",
    "d4 = len(agent4)\n",
    "d5 = len(agent5)\n",
    "d6 = len(agent6)\n",
    "d7 = len(agent7)\n",
    "d8 = len(agent8)\n",
    "\n",
    "train1 = agent1[:int(train_ratio * d1)]\n",
    "valid1 = agent1[int(train_ratio * d1):int((train_ratio + valid_ratio) * d1) ]\n",
    "test1 = agent1[int((train_ratio + valid_ratio) * d1): ]\n",
    "\n",
    "train2 = agent2[:int(train_ratio * d2)]\n",
    "valid2 = agent2[int(train_ratio * d2):int((train_ratio + valid_ratio) * d2) ]\n",
    "test2 = agent2[int((train_ratio + valid_ratio) * d2): ]\n",
    "\n",
    "train3 = agent3[:int(train_ratio * d3)]\n",
    "valid3 = agent3[int(train_ratio * d3):int((train_ratio + valid_ratio) * d3)]\n",
    "test3 = agent3[int((train_ratio + valid_ratio) * d3):]\n",
    "\n",
    "train4 = agent4[:int(train_ratio * d4)]\n",
    "valid4 = agent4[int(train_ratio * d4):int((train_ratio + valid_ratio) * d4)]\n",
    "test4 = agent4[int((train_ratio + valid_ratio) * d4):]\n",
    "\n",
    "train5 = agent5[:int(train_ratio * d5)]\n",
    "valid5 = agent5[int(train_ratio * d5):int((train_ratio + valid_ratio) * d5)]\n",
    "test5 = agent5[int((train_ratio + valid_ratio) * d5):]\n",
    "\n",
    "train6 = agent6[:int(train_ratio * d6)]\n",
    "valid6 = agent6[int(train_ratio * d6):int((train_ratio + valid_ratio) * d6)]\n",
    "test6 = agent6[int((train_ratio + valid_ratio) * d6):]\n",
    "\n",
    "train7 = agent7[:int(train_ratio * d7)]\n",
    "valid7 = agent7[int(train_ratio * d7):int((train_ratio + valid_ratio) * d7)]\n",
    "test7 = agent7[int((train_ratio + valid_ratio) * d7):]\n",
    "\n",
    "train8 = agent8[:int(train_ratio * d8)]\n",
    "valid8 = agent8[int(train_ratio * d8):int((train_ratio + valid_ratio) * d8)]\n",
    "test8 = agent8[int((train_ratio + valid_ratio) * d8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = len(agent1)\n",
    "q2 = len(agent2)\n",
    "q3 = len(agent3)\n",
    "q4 = len(agent4)\n",
    "q5 = len(agent5)\n",
    "q6 = len(agent6)\n",
    "q7 = len(agent7)\n",
    "q8 = len(agent8)\n",
    "\n",
    "qtrain1 = agent1[:int(train_ratio * q1)]\n",
    "qvalid1 = agent1[int(train_ratio * q1):int((train_ratio + valid_ratio) * q1)]\n",
    "qtest1 = agent1[int((train_ratio + valid_ratio) * q1):]\n",
    "\n",
    "qtrain2 = agent2[:int(train_ratio * q2)]\n",
    "qvalid2 = agent2[int(train_ratio * q2):int((train_ratio + valid_ratio) * q2)]\n",
    "qtest2 = agent2[int((train_ratio + valid_ratio) * q2):]\n",
    "\n",
    "qtrain3 = agent3[:int(train_ratio * q3)]\n",
    "qvalid3 = agent3[int(train_ratio * q3):int((train_ratio + valid_ratio) * q3)]\n",
    "qtest3 = agent3[int((train_ratio + valid_ratio) * q3):]\n",
    "\n",
    "qtrain4 = agent4[:int(train_ratio * q4)]\n",
    "qvalid4 = agent4[int(train_ratio * q4):int((train_ratio + valid_ratio) * q4)]\n",
    "qtest4 = agent4[int((train_ratio + valid_ratio) * q4):]\n",
    "\n",
    "qtrain5 = agent5[:int(train_ratio * q5)]\n",
    "qvalid5 = agent5[int(train_ratio * q5):int((train_ratio + valid_ratio) * q5)]\n",
    "qtest5 = agent5[int((train_ratio + valid_ratio) * q5):]\n",
    "\n",
    "qtrain6 = agent6[:int(train_ratio * q6)]\n",
    "qvalid6 = agent6[int(train_ratio * q6):int((train_ratio + valid_ratio) * q6)]\n",
    "qtest6 = agent6[int((train_ratio + valid_ratio) * q6):]\n",
    "\n",
    "qtrain7 = agent7[:int(train_ratio * q7)]\n",
    "qvalid7 = agent7[int(train_ratio * q7):int((train_ratio + valid_ratio) * q7)]\n",
    "qtest7 = agent7[int((train_ratio + valid_ratio) * q7):]\n",
    "\n",
    "qtrain8 = agent8[:int(train_ratio * q8)]\n",
    "qvalid8 = agent8[int(train_ratio * q8):int((train_ratio + valid_ratio) * q8)]\n",
    "qtest8 = agent8[int((train_ratio + valid_ratio) * q8):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample Sizes\n",
    "s = 100000\n",
    "n = 12500\n",
    "\n",
    "train = train1[:s] + train2[:s] + train3[:s] + train4[:s] + train5[:s] + train6[:s] + train7[:s] + train8[:s]\n",
    "valid = valid1[:n] + valid2[:n] + valid3[:n] + valid4[:n] + valid5[:n] + valid6[:n] + valid7[:n] + valid8[:n] \n",
    "test = test1[:n] + test2[:n] + test3[:n] + test4[:n] + test5[:n] + test6[:n] + test7[:n] + test8[:n]\n",
    "\n",
    "\n",
    "qtrain = qtrain1[:s] + qtrain2[:s] + qtrain3[:s] + qtrain4[:s] + qtrain5[:s] + qtrain6[:s] + qtrain7[:s] + qtrain8[:s]\n",
    "qvalid = qvalid1[:n] + qvalid2[:n] + qvalid3[:n] + qvalid4[:n] + qvalid5[:n] + qvalid6[:n] + qvalid7[:n] + qvalid8[:n] \n",
    "qtest = qtest1[:n] + qtest2[:n] + qtest3[:n] + qtest4[:n] + qtest5[:n] + qtest6[:n] + qtest7[:n] + qtest8[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EpisodeDataset(train, token_to_idx)\n",
    "valid_dataset = EpisodeDataset(valid, token_to_idx)\n",
    "test_dataset = EpisodeDataset(test, token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(vocab_size, block_size, n_layer=num_layers, n_head=num_layers, n_embd=embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_pipeline(folder_path: str, num_samples: int, layers: list, linear, model_load_path, train_random):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for i in layers:\n",
    "\n",
    "        curr_path = os.path.join(folder_path, f\"Layer_{i}\")\n",
    "\n",
    "        if not os.path.exists(curr_path):\n",
    "            os.makedirs(curr_path)\n",
    "        \n",
    "        print(f\"Layer {i}\")\n",
    "        \n",
    "        # Retreive Embeddings and Normalize Q-Values\n",
    "\n",
    "        embed_train, qval_train = get_embeddings_qvalues(num_samples, train, qtrain, i, config, token_to_idx, model_load_path = model_load_path, data_path = 'sampled_q_vals_train.pkl')\n",
    "        embed_valid, qval_valid = get_embeddings_qvalues(num_samples, valid, qvalid, i, config, token_to_idx, model_load_path = model_load_path, data_path = 'sampled_q_vals_valid.pkl')\n",
    "        embed_test, qval_test = get_embeddings_qvalues(num_samples, test, qtest, i, config, token_to_idx, model_load_path = model_load_path, data_path = 'sampled_q_vals_test.pkl')\n",
    "\n",
    "        qval_train_norm, min, max = min_max_normalization(qval_train)\n",
    "        qval_valid_norm = min_max_normalization(qval_valid, min, max)\n",
    "        qval_test_norm = min_max_normalization(qval_test, min, max)\n",
    "\n",
    "        d = len(qval_train_norm[0])\n",
    "        n = embed_train[0].shape[0]\n",
    "\n",
    "        # Non-Random\n",
    "\n",
    "        probe_dataset_train = ProbeDataset(embed_train, qval_train_norm)\n",
    "        probe_dataset_valid = ProbeDataset(embed_valid, qval_valid_norm)\n",
    "        probe_dataset_test = ProbeDataset(embed_test, qval_test_norm)\n",
    "\n",
    "        print(\"\\nTraining Normal Probe\\n\")\n",
    "        model_path, train_loss, valid_loss = train_probe(probe_dataset_train, probe_dataset_valid, device = device, epochs = 50, params = (d, n), model_dir = os.path.join(curr_path, f\"Non_Random_Layer_{i}\"), linear=linear)\n",
    "\n",
    "        with open(os.path.join(curr_path, \"normal_train_loss\"), 'wb') as f:\n",
    "            pickle.dump(train_loss, f)\n",
    "        with open(os.path.join(curr_path, \"normal_valid_loss\"), 'wb') as f:\n",
    "            pickle.dump(valid_loss, f)\n",
    "\n",
    "        test_loss = test_probe(probe_dataset_test, model_path, (d, n), device, linear)\n",
    "        print(f\"MSE Loss: {test_loss:.4f}\")\n",
    "\n",
    "        if train_random:\n",
    "\n",
    "            # Random\n",
    "        \n",
    "            random_embeddings_train = [torch.randn(512, 1) for _ in range(len(embed_train))]\n",
    "            random_embeddings_valid = [torch.randn(512, 1) for _ in range(len(embed_valid))]\n",
    "            random_embeddings_test = [torch.randn(512, 1) for _ in range(len(embed_test))]\n",
    "            \n",
    "            random_dataset_train = ProbeDataset(random_embeddings_train, qval_train_norm)\n",
    "            random_dataset_valid = ProbeDataset(random_embeddings_valid, qval_valid_norm)\n",
    "            random_dataset_test = ProbeDataset(random_embeddings_test, qval_test_norm)\n",
    "    \n",
    "            print(\"\\nTraining Random Probe\\n\")\n",
    "            random_path, random_train_loss, random_valid_loss = train_probe(random_dataset_train, random_dataset_valid, device = device, epochs = 50, params = (d, n), model_dir = os.path.join(curr_path, f\"Random_Layer_{i}\"), linear=linear)\n",
    "    \n",
    "            with open(os.path.join(curr_path, \"random_train_loss\"), 'wb') as f:\n",
    "                pickle.dump(random_train_loss, f)\n",
    "            with open(os.path.join(curr_path, \"random_valid_loss\"), 'wb') as f:\n",
    "                pickle.dump(random_valid_loss, f)\n",
    "    \n",
    "            rand_loss = test_probe(random_dataset_test, random_path, (d, n), device, linear)\n",
    "            print(f\"Random MSE Loss: {rand_loss:.4f}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 5, Min MSE Loss: 0.11358589092565267\n",
      "MSE Loss: 0.1162\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n",
      "Layer 2\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 9, Min MSE Loss: 0.11317466846774966\n",
      "MSE Loss: 0.1144\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n",
      "Layer 3\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 9, Min MSE Loss: 0.11355891705450623\n",
      "MSE Loss: 0.1147\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n",
      "Layer 4\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 14, Min MSE Loss: 0.11391765904622314\n",
      "MSE Loss: 0.1138\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n",
      "Layer 5\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 14, Min MSE Loss: 0.11385590993179523\n",
      "MSE Loss: 0.1136\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n",
      "Layer 6\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 22, Min MSE Loss: 0.1137680464727575\n",
      "MSE Loss: 0.1163\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n",
      "Layer 7\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 22, Min MSE Loss: 0.11374321603888109\n",
      "MSE Loss: 0.1153\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n",
      "Layer 8\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 22, Min MSE Loss: 0.11359036154539227\n",
      "MSE Loss: 0.1157\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_pipeline(folder_path = 'Nonlinear_Probe', num_samples = 8, layers = list(range(1, 9)), linear = False, model_load_path = 'Model_12.pth', train_random = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
