{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from generate_embeddings_gridworld import get_embeddings_qvalues, min_max_normalization\n",
    "from probe import ProbeDataset, train_probe, test_probe\n",
    "from GPT.dataset import EpisodeDataset\n",
    "from GPT.model import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_idx = {(i, j): i * 9 + j + 1 for i in range(9) for j in range(9)} | {\"up\": 82, \"down\": 83, \"left\": 84, \"right\": 85}\n",
    "token_to_idx['<pad>'] = 0  # Padding token\n",
    "\n",
    "vocab_size = 86\n",
    "block_size = 200\n",
    "embed_size = 512\n",
    "num_heads = 8\n",
    "num_layers = 8\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, 'train00.pkl'), 'rb') as f:\n",
    "    agent00 = pickle.load(f)\n",
    "with open(os.path.join(path, 'train08.pkl'), 'rb') as f:\n",
    "    agent08 = pickle.load(f)\n",
    "with open(os.path.join(path, 'train80.pkl'), 'rb') as f:\n",
    "    agent80 = pickle.load(f)\n",
    "with open(os.path.join(path, 'train88.pkl'), 'rb') as f:\n",
    "    agent88 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, 'qhist00.pkl'), 'rb') as f:\n",
    "    qhist00 = pickle.load(f)\n",
    "with open(os.path.join(path, 'qhist08.pkl'), 'rb') as f:\n",
    "    qhist08 = pickle.load(f)\n",
    "with open(os.path.join(path, 'qhist80.pkl'), 'rb') as f:\n",
    "    qhist80 = pickle.load(f)\n",
    "with open(os.path.join(path, 'qhist88.pkl'), 'rb') as f:\n",
    "    qhist88 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "valid_ratio = 0.1\n",
    "\n",
    "d00 = len(agent00)\n",
    "d08 = len(agent08)\n",
    "d80 = len(agent80)\n",
    "d88 = len(agent88)\n",
    "\n",
    "train00 = agent00[:int(train_ratio * d00)]\n",
    "valid00 = agent00[int(train_ratio * d00):int((train_ratio + valid_ratio) * d00) ]\n",
    "test00 = agent00[int((train_ratio + valid_ratio) * d00): ]\n",
    "\n",
    "train08 = agent08[:int(train_ratio * d08)]\n",
    "valid08 = agent08[int(train_ratio * d08):int((train_ratio + valid_ratio) * d08) ]\n",
    "test08 = agent08[int((train_ratio + valid_ratio) * d08): ]\n",
    "\n",
    "train80 = agent80[:int(train_ratio * d80)]\n",
    "valid80 = agent80[int(train_ratio * d80):int((train_ratio + valid_ratio) * d80) ]\n",
    "test80 = agent80[int((train_ratio + valid_ratio) * d80): ]\n",
    "\n",
    "train88 = agent88[:int(train_ratio * d88)]\n",
    "valid88 = agent88[int(train_ratio * d88):int((train_ratio + valid_ratio) * d88) ]\n",
    "test88 = agent88[int((train_ratio + valid_ratio) * d88): ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtrain00 = qhist00[:int(train_ratio * d00)]\n",
    "qvalid00 = qhist00[int(train_ratio * d00):int((train_ratio + valid_ratio) * d00)]\n",
    "qtest00 = qhist00[int((train_ratio + valid_ratio) * d00):]\n",
    "\n",
    "qtrain08 = qhist08[:int(train_ratio * d08)]\n",
    "qvalid08 = qhist08[int(train_ratio * d08):int((train_ratio + valid_ratio) * d08)]\n",
    "qtest08 = qhist08[int((train_ratio + valid_ratio) * d08):]\n",
    "\n",
    "qtrain80 = qhist80[:int(train_ratio * d80)]\n",
    "qvalid80 = qhist80[int(train_ratio * d80):int((train_ratio + valid_ratio) * d80)]\n",
    "qtest80 = qhist80[int((train_ratio + valid_ratio) * d80):]\n",
    "\n",
    "qtrain88 = qhist88[:int(train_ratio * d88)]\n",
    "qvalid88 = qhist88[int(train_ratio * d88):int((train_ratio + valid_ratio) * d88)]\n",
    "qtest88 = qhist88[int((train_ratio + valid_ratio) * d88):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample Sizes\n",
    "s = 100000\n",
    "n = 12500\n",
    "\n",
    "train = train00[:s] + train08[:s] + train80[:s] + train88[:s]\n",
    "valid = valid00[:n] + valid08[:n] + valid80[:n] + valid88[:n]\n",
    "test = test00[:n] + test08[:n] + test80[:n] + test88[:n]\n",
    "\n",
    "\n",
    "qtrain = qtrain00[:s] + qtrain08[:s] + qtrain80[:s] + qtrain88[:s]\n",
    "qvalid = qvalid00[:n] + qvalid08[:n] + qvalid80[:n] + qvalid88[:n]\n",
    "qtest = qtest00[:n] + qtest08[:n] + qtest80[:n] + qtest88[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EpisodeDataset(train, token_to_idx)\n",
    "valid_dataset = EpisodeDataset(valid, token_to_idx)\n",
    "test_dataset = EpisodeDataset(test, token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(vocab_size, block_size, n_layer=num_layers, n_head=num_layers, n_embd=embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_pipeline(folder_path: str, positions: list, layers: list, linear, model_load_path, train_random):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for i in layers:\n",
    "\n",
    "        curr_path = os.path.join(folder_path, f\"Layer_{i}\")\n",
    "\n",
    "        if not os.path.exists(curr_path):\n",
    "            os.makedirs(curr_path)\n",
    "        \n",
    "        print(f\"Layer {i}\")\n",
    "        \n",
    "        # Retreive Embeddings and Normalize Q-Values\n",
    "\n",
    "        embed_train, qval_train = get_embeddings_qvalues(positions, train, qtrain, i, config, token_to_idx, cutoff = 30, model_load_path = model_load_path)\n",
    "        embed_valid, qval_valid = get_embeddings_qvalues(positions, valid, qvalid, i, config, token_to_idx, cutoff = 30, model_load_path = model_load_path)\n",
    "        embed_test, qval_test = get_embeddings_qvalues(positions, test, qtest, i, config, token_to_idx, cutoff = 30, model_load_path = model_load_path)\n",
    "\n",
    "        qval_train_norm, min, max = min_max_normalization(qval_train)\n",
    "        qval_valid_norm = min_max_normalization(qval_valid, min, max)\n",
    "        qval_test_norm = min_max_normalization(qval_test, min, max)\n",
    "\n",
    "        d = len(qval_train_norm[0])\n",
    "        n = embed_train[0].shape[0]\n",
    "\n",
    "        # Non-Random\n",
    "\n",
    "        probe_dataset_train = ProbeDataset(embed_train, qval_train_norm)\n",
    "        probe_dataset_valid = ProbeDataset(embed_valid, qval_valid_norm)\n",
    "        probe_dataset_test = ProbeDataset(embed_test, qval_test_norm)\n",
    "\n",
    "        print(\"\\nTraining Normal Probe\\n\")\n",
    "        model_path, train_loss, valid_loss = train_probe(probe_dataset_train, probe_dataset_valid, device = device, epochs = 50, params = (d, n), model_dir = os.path.join(curr_path, f\"Non_Random_Layer_{i}\"), linear=linear)\n",
    "\n",
    "        with open(os.path.join(curr_path, \"normal_train_loss\"), 'wb') as f:\n",
    "            pickle.dump(train_loss, f)\n",
    "        with open(os.path.join(curr_path, \"normal_valid_loss\"), 'wb') as f:\n",
    "            pickle.dump(valid_loss, f)\n",
    "\n",
    "        test_loss = test_probe(probe_dataset_test, model_path, (d, n), device, linear)\n",
    "        print(f\"MSE Loss: {test_loss:.4f}\")\n",
    "\n",
    "        if train_random:\n",
    "\n",
    "            # Random\n",
    "        \n",
    "            random_embeddings_train = [torch.randn(512, 1) for _ in range(len(embed_train))]\n",
    "            random_embeddings_valid = [torch.randn(512, 1) for _ in range(len(embed_valid))]\n",
    "            random_embeddings_test = [torch.randn(512, 1) for _ in range(len(embed_test))]\n",
    "            \n",
    "            random_dataset_train = ProbeDataset(random_embeddings_train, qval_train_norm)\n",
    "            random_dataset_valid = ProbeDataset(random_embeddings_valid, qval_valid_norm)\n",
    "            random_dataset_test = ProbeDataset(random_embeddings_test, qval_test_norm)\n",
    "    \n",
    "            print(\"\\nTraining Random Probe\\n\")\n",
    "            random_path, random_train_loss, random_valid_loss = train_probe(random_dataset_train, random_dataset_valid, device = device, epochs = 50, params = (d, n), model_dir = os.path.join(curr_path, f\"Random_Layer_{i}\"), linear=linear)\n",
    "    \n",
    "            with open(os.path.join(curr_path, \"random_train_loss\"), 'wb') as f:\n",
    "                pickle.dump(random_train_loss, f)\n",
    "            with open(os.path.join(curr_path, \"random_valid_loss\"), 'wb') as f:\n",
    "                pickle.dump(random_valid_loss, f)\n",
    "    \n",
    "            rand_loss = test_probe(random_dataset_test, random_path, (d, n), device, linear)\n",
    "            print(f\"Random MSE Loss: {rand_loss:.4f}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 5, Min MSE Loss: 0.11358589092565267\n",
      "MSE Loss: 0.1162\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n",
      "Layer 2\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 9, Min MSE Loss: 0.11317466846774966\n",
      "MSE Loss: 0.1144\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n",
      "Layer 3\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 9, Min MSE Loss: 0.11355891705450623\n",
      "MSE Loss: 0.1147\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n",
      "Layer 4\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 14, Min MSE Loss: 0.11391765904622314\n",
      "MSE Loss: 0.1138\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n",
      "Layer 5\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 14, Min MSE Loss: 0.11385590993179523\n",
      "MSE Loss: 0.1136\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n",
      "Layer 6\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 22, Min MSE Loss: 0.1137680464727575\n",
      "MSE Loss: 0.1163\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n",
      "Layer 7\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 22, Min MSE Loss: 0.11374321603888109\n",
      "MSE Loss: 0.1153\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n",
      "Layer 8\n",
      "\n",
      "Training Normal Probe\n",
      "\n",
      "Best Epoch: 22, Min MSE Loss: 0.11359036154539227\n",
      "MSE Loss: 0.1157\n",
      "\n",
      "Training Random Probe\n",
      "\n",
      "Best Epoch: 3, Min MSE Loss: 0.14671152819063624\n",
      "Random MSE Loss: 0.1487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_pipeline(folder_path = 'Nonlinear_Probe', positions = [(2, 2), (2, 6), (6, 2), (6, 6)], layers = list(range(1, 9)), linear = False, model_load_path = 'Model_12.pth', train_random = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
