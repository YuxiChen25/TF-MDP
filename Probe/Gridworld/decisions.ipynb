{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from generate_embeddings_gridworld import get_embeddings_qvalues, min_max_normalization\n",
    "from probe import LinearProbe, NonLinearProbe, ProbeDataset, train_probe, test_probe\n",
    "from GPT.dataset import EpisodeDataset\n",
    "from GPT.model import Config, GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_idx = {(i, j): i * 9 + j + 1 for i in range(9) for j in range(9)} | {\"up\": 82, \"down\": 83, \"left\": 84, \"right\": 85}\n",
    "token_to_idx['<pad>'] = 0  # Padding token\n",
    "\n",
    "vocab_size = 86\n",
    "block_size = 200\n",
    "embed_size = 512\n",
    "num_heads = 8\n",
    "num_layers = 8\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, 'train00.pkl'), 'rb') as f:\n",
    "    agent00 = pickle.load(f)\n",
    "with open(os.path.join(path, 'train08.pkl'), 'rb') as f:\n",
    "    agent08 = pickle.load(f)\n",
    "with open(os.path.join(path, 'train80.pkl'), 'rb') as f:\n",
    "    agent80 = pickle.load(f)\n",
    "with open(os.path.join(path, 'train88.pkl'), 'rb') as f:\n",
    "    agent88 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, 'qhist00.pkl'), 'rb') as f:\n",
    "    qhist00 = pickle.load(f)\n",
    "with open(os.path.join(path, 'qhist08.pkl'), 'rb') as f:\n",
    "    qhist08 = pickle.load(f)\n",
    "with open(os.path.join(path, 'qhist80.pkl'), 'rb') as f:\n",
    "    qhist80 = pickle.load(f)\n",
    "with open(os.path.join(path, 'qhist88.pkl'), 'rb') as f:\n",
    "    qhist88 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "valid_ratio = 0.1\n",
    "\n",
    "d00 = len(agent00)\n",
    "d08 = len(agent08)\n",
    "d80 = len(agent80)\n",
    "d88 = len(agent88)\n",
    "\n",
    "train00 = agent00[:int(train_ratio * d00)]\n",
    "valid00 = agent00[int(train_ratio * d00):int((train_ratio + valid_ratio) * d00) ]\n",
    "test00 = agent00[int((train_ratio + valid_ratio) * d00): ]\n",
    "\n",
    "train08 = agent08[:int(train_ratio * d08)]\n",
    "valid08 = agent08[int(train_ratio * d08):int((train_ratio + valid_ratio) * d08) ]\n",
    "test08 = agent08[int((train_ratio + valid_ratio) * d08): ]\n",
    "\n",
    "train80 = agent80[:int(train_ratio * d80)]\n",
    "valid80 = agent80[int(train_ratio * d80):int((train_ratio + valid_ratio) * d80) ]\n",
    "test80 = agent80[int((train_ratio + valid_ratio) * d80): ]\n",
    "\n",
    "train88 = agent88[:int(train_ratio * d88)]\n",
    "valid88 = agent88[int(train_ratio * d88):int((train_ratio + valid_ratio) * d88) ]\n",
    "test88 = agent88[int((train_ratio + valid_ratio) * d88): ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtrain00 = qhist00[:int(train_ratio * d00)]\n",
    "qvalid00 = qhist00[int(train_ratio * d00):int((train_ratio + valid_ratio) * d00)]\n",
    "qtest00 = qhist00[int((train_ratio + valid_ratio) * d00):]\n",
    "\n",
    "qtrain08 = qhist08[:int(train_ratio * d08)]\n",
    "qvalid08 = qhist08[int(train_ratio * d08):int((train_ratio + valid_ratio) * d08)]\n",
    "qtest08 = qhist08[int((train_ratio + valid_ratio) * d08):]\n",
    "\n",
    "qtrain80 = qhist80[:int(train_ratio * d80)]\n",
    "qvalid80 = qhist80[int(train_ratio * d80):int((train_ratio + valid_ratio) * d80)]\n",
    "qtest80 = qhist80[int((train_ratio + valid_ratio) * d80):]\n",
    "\n",
    "qtrain88 = qhist88[:int(train_ratio * d88)]\n",
    "qvalid88 = qhist88[int(train_ratio * d88):int((train_ratio + valid_ratio) * d88)]\n",
    "qtest88 = qhist88[int((train_ratio + valid_ratio) * d88):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample Sizes\n",
    "s = 100000\n",
    "n = 12500\n",
    "\n",
    "train = train00[:s] + train08[:s] + train80[:s] + train88[:s]\n",
    "valid = valid00[:n] + valid08[:n] + valid80[:n] + valid88[:n]\n",
    "test = test00[:n] + test08[:n] + test80[:n] + test88[:n]\n",
    "\n",
    "\n",
    "qtrain = qtrain00[:s] + qtrain08[:s] + qtrain80[:s] + qtrain88[:s]\n",
    "qvalid = qvalid00[:n] + qvalid08[:n] + qvalid80[:n] + qvalid88[:n]\n",
    "qtest = qtest00[:n] + qtest08[:n] + qtest80[:n] + qtest88[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EpisodeDataset(train, token_to_idx)\n",
    "valid_dataset = EpisodeDataset(valid, token_to_idx)\n",
    "test_dataset = EpisodeDataset(test, token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(vocab_size, block_size, n_layer=num_layers, n_head=num_layers, n_embd=embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mega_training_pipeline(folder_path: str, positions: list, layers: list, model_load_path):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for i in layers:\n",
    "\n",
    "        curr_path = os.path.join(folder_path, f\"Layer_{i}\")\n",
    "\n",
    "        if not os.path.exists(curr_path):\n",
    "            os.makedirs(curr_path)\n",
    "        \n",
    "        print(f\"Layer {i}\")\n",
    "        \n",
    "        # Retreive Embeddings and Normalize Q-Values\n",
    "\n",
    "        embed_train, qval_train = get_embeddings_qvalues(positions, train, qtrain, i, config, token_to_idx, cutoff = 30, model_load_path = model_load_path)\n",
    "        embed_valid, qval_valid = get_embeddings_qvalues(positions, valid, qvalid, i, config, token_to_idx, cutoff = 30, model_load_path = model_load_path)\n",
    "        embed_test, qval_test = get_embeddings_qvalues(positions, test, qtest, i, config, token_to_idx, cutoff = 30, model_load_path = model_load_path)\n",
    "\n",
    "        qval_train_norm, min, max = min_max_normalization(qval_train)\n",
    "        qval_valid_norm = min_max_normalization(qval_valid, min, max)\n",
    "        qval_test_norm = min_max_normalization(qval_test, min, max)\n",
    "\n",
    "        d = len(qval_train_norm[0])\n",
    "        n = embed_train[0].shape[0]\n",
    "\n",
    "        # Non-Random\n",
    "\n",
    "        probe_dataset_train = ProbeDataset(embed_train, qval_train_norm)\n",
    "        probe_dataset_valid = ProbeDataset(embed_valid, qval_valid_norm)\n",
    "        probe_dataset_test = ProbeDataset(embed_test, qval_test_norm)\n",
    "\n",
    "        print(\"\\nTraining Linear Probe\\n\")\n",
    "        model_path_linear, _, _ = train_probe(probe_dataset_train, probe_dataset_valid, device = device, epochs = 100, params = (d, n), model_dir = os.path.join(curr_path, f\"Linear_Layer_{i}\"), linear=True)\n",
    "        test_loss_linear = test_probe(probe_dataset_test, model_path_linear, (d, n), device, linear = True)\n",
    "        print(f\"MSE Loss Linear: {test_loss_linear:.4f}\")\n",
    "\n",
    "        print(\"\\nTraining Nonlinear Probe\\n\")\n",
    "        model_path_nonlin, _, _ = train_probe(probe_dataset_train, probe_dataset_valid, device = device, epochs = 100, params = (d, n), model_dir = os.path.join(curr_path, f\"Nonlinear_Layer_{i}\"), linear=False)\n",
    "        test_loss_nonlin = test_probe(probe_dataset_test, model_path_nonlin, (d, n), device, linear = False)\n",
    "        print(f\"MSE Loss Nonlinear: {test_loss_nonlin:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 7\n",
      "\n",
      "Training Linear Probe\n",
      "\n",
      "Best Epoch: 90, Min MSE Loss: 0.06121562799219897\n",
      "MSE Loss Linear: 0.0607\n",
      "\n",
      "Training Nonlinear Probe\n",
      "\n",
      "Best Epoch: 16, Min MSE Loss: 0.05889081619028584\n",
      "MSE Loss Nonlinear: 0.0578\n",
      "Layer 8\n",
      "\n",
      "Training Linear Probe\n",
      "\n",
      "Best Epoch: 82, Min MSE Loss: 0.061162354209258585\n",
      "MSE Loss Linear: 0.0614\n",
      "\n",
      "Training Nonlinear Probe\n",
      "\n",
      "Best Epoch: 9, Min MSE Loss: 0.058891325965519645\n"
     ]
    }
   ],
   "source": [
    "mega_training_pipeline('Mega Probe', [(0, 0), (8, 0), (0, 8), (8, 8), (2, 2), (2, 6), (6, 2), (6, 6), (4, 2), (4, 6), (2, 4), (6, 4), (4, 0), (4, 8), (0, 4), (0, 8)], layers = [7, 8], model_load_path = 'Model_12.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_turns(starting_pos, model, layer, probe, device):\n",
    "\n",
    "    get_direction = lambda x: {0: \"up\", 1: \"down\", 2: \"left\", 3: \"right\"}[torch.argmax(x).item()]\n",
    "\n",
    "    directions = {\n",
    "        \"up\": (0, 1),\n",
    "        \"down\": (0, -1),\n",
    "        \"left\": (-1, 0),\n",
    "        \"right\": (1, 0),\n",
    "    }\n",
    "\n",
    "    curr_pos = starting_pos\n",
    "    X = [starting_pos]\n",
    "\n",
    "    while curr_pos != (4, 4):\n",
    "        \n",
    "        X_idx = [token_to_idx[token] for token in X]\n",
    "        X_idx = torch.tensor(X_idx, dtype=torch.long).to(device)\n",
    "        X_idx = X_idx.unsqueeze(0)\n",
    "\n",
    "        embedding = model(X_idx, layer)[:, len(X) - 1, :]\n",
    "        cpu_embed = embedding.cpu()\n",
    "        pred = probe.predict(cpu_embed, device)\n",
    "\n",
    "        direction = get_direction(pred)\n",
    "\n",
    "        dx, dy = directions[direction]\n",
    "        new_pos = (curr_pos[0] + dx, curr_pos[1] + dy)\n",
    "\n",
    "        curr_pos = new_pos\n",
    "        X.append(direction)\n",
    "        X.append(curr_pos) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisions_validate(probe_model_path, gpt_model_path, config, linear):\n",
    "    success_count = 0\n",
    "    total_attempts = 0\n",
    "\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "            \n",
    "    if linear:\n",
    "        probe = LinearProbe(4, 512).to(device)\n",
    "    else:\n",
    "        probe = NonLinearProbe(4, 512).to(device)\n",
    "    probe.load_state_dict(torch.load(probe_model_path, map_location = device))\n",
    "\n",
    "    model = GPTModel(config).to(device)\n",
    "    model.load_state_dict(torch.load(gpt_model_path))\n",
    "\n",
    "    itrs = 100\n",
    "\n",
    "    for _ in range(itrs):\n",
    "        for i in range(9):\n",
    "            for j in range(9):\n",
    "                if (i, j) == (4, 4):\n",
    "                    continue   \n",
    "                total_attempts += 1\n",
    "                try:\n",
    "                    take_turns((i, j), model, 6, probe, device)\n",
    "                    success_count += 1\n",
    "                except (KeyError, AssertionError):\n",
    "                    continue\n",
    "\n",
    "    success_rate = success_count / total_attempts   \n",
    "    print(f\"Success rate: {success_rate:.2f} ({success_count}/{total_attempts})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0.97 (7800/8000)\n",
      "Success rate: 0.66 (5251/8000)\n"
     ]
    }
   ],
   "source": [
    "decisions_validate(probe_model_path = 'Mega Probe/Layer_7/Linear_Layer_7/best_model.pth', gpt_model_path = 'Model_12.pth', config = config, linear = True)\n",
    "decisions_validate(probe_model_path = 'Mega Probe/Layer_7/Nonlinear_Layer_7/best_model.pth', gpt_model_path = 'Model_12.pth', config = config, linear = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0.95 (7569/8000)\n",
      "Success rate: 0.91 (7262/8000)\n"
     ]
    }
   ],
   "source": [
    "decisions_validate(probe_model_path = 'Mega Probe/Layer_8/Linear_Layer_8/best_model.pth', gpt_model_path = 'Model_12.pth', config = config, linear = True)\n",
    "decisions_validate(probe_model_path = 'Mega Probe/Layer_8/Nonlinear_Layer_8/best_model.pth', gpt_model_path = 'Model_12.pth', config = config, linear = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
